{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_data(X_train, y_train, X_test, y_test, experiment, system):\n",
    "    if \"win\" in system.lower():\n",
    "        base_path = \"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\" #Windows\n",
    "    elif \"lin\" in system.lower():\n",
    "        base_path = \"/home/propietari/Documents/GitHub/policy-data-analyzer/tasks/data_augmentation/output/HSSC/\" #linux\n",
    "        \n",
    "    filename = f\"{experiment}_train_sentences.csv\"\n",
    "    file = base_path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_train))\n",
    "\n",
    "    filename = f\"{experiment}_train_labels.csv\"\n",
    "    file = base_path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_train))\n",
    "\n",
    "    filename = f\"{experiment}_test_sentences.csv\"\n",
    "    file = base_path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_test))\n",
    "\n",
    "    filename = f\"{experiment}_test_labels.csv\"\n",
    "    file = base_path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_test))\n",
    "        \n",
    "def load_dictionary(file):\n",
    "    with open(file, 'r') as f:\n",
    "        dictionary = json.load(f)\n",
    "    return dictionary\n",
    "\n",
    "def check_labels(data_frame, column_name):\n",
    "    print(data_frame[column_name].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval from Excel sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Technical assistance' nan 'Supplies' 'Loan' 'Direct payment'\n",
      " 'Tax benefit' 'Fine']\n",
      "2673\n",
      "836\n"
     ]
    }
   ],
   "source": [
    "#To process the Excel file with assisted labeling results\n",
    "\n",
    "path = \"/home/propietari/Documents/GitHub/policy-data-analyzer/tasks/data_augmentation/input/\" #Linux\n",
    "# path = \"C:/Users/jordi/Documents/GitHub/policy-data-analyzer/tasks/data_augmentation/input/\" #Windows\n",
    "filename = \"pre_labeled_Spanish_ready_short.xlsx\"\n",
    "file = path + filename\n",
    "\n",
    "policy_counter = {\"Loan\" : 0, \"Direct payment\" : 0, \"Fine\" : 0, \"Supplies\" : 0, \"Tax benefit\" : 0, \"Technical assistance\" : 0}\n",
    "\n",
    "for policy in policy_counter:\n",
    "    df_temp = pd.read_excel(file, engine='openpyxl', sheet_name = policy, skiprows=[0])\n",
    "    df_temp.loc[df_temp['Is_policy'] == 1.0, 'Is_policy'] = policy\n",
    "    if \"Other_instrument\"in df_temp.columns:\n",
    "        df_temp['Is_policy'] = np.where(df_temp['Is_policy'] == 0.0, df_temp['Other_instrument'], df_temp['Is_policy'])\n",
    "    df_temp.loc[df_temp['Is_policy'] == \"Unknown\", 'Is_policy'] = np.NaN\n",
    "    df_temp.loc[df_temp['Is_policy'] == \"Instrument unknown\", 'Is_policy'] = np.NaN\n",
    "    df_temp.loc[df_temp['Is_policy'] == \"Tax\", 'Is_policy'] = \"Tax benefit\"\n",
    "    df_temp.loc[df_temp['Is_policy'] == \"Tax deduction\", 'Is_policy'] = \"Tax benefit\"\n",
    "    df_temp.loc[df_temp['Is_policy'] == \"Technical\", 'Is_policy'] = \"Technical assistance\"\n",
    "    df_temp.loc[df_temp['Is_policy'] == \"Direct\", 'Is_policy'] = \"Direct payment\"\n",
    "    df_temp.loc[df_temp['Is_policy'] == \"Credit\", 'Is_policy'] = \"Loan\"\n",
    "    df_temp['Is_policy'] = df_temp['Is_policy'].str.strip()\n",
    "    df_temp.loc[df_temp['Is_incentive'] == 0.0, 'Is_incentive'] = \"not_Incentive\"\n",
    "    df_temp.loc[df_temp['Is_incentive'] == 1.0, 'Is_incentive'] = \"Incentive\"\n",
    "    try:\n",
    "        df_binary = pd.concat([df_binary, df_temp[['Sentence', 'Is_incentive']]], ignore_index = True)\n",
    "        df_multiclass = pd.concat([df_multiclass, df_temp[['Sentence', 'Is_policy']]], ignore_index = True)\n",
    "    except:\n",
    "        df_binary = df_temp[['Sentence', 'Is_incentive']]\n",
    "        df_multiclass = df_temp[['Sentence', 'Is_policy']]\n",
    "\n",
    "binary_assisted_spanish = df_binary.dropna().values.tolist()\n",
    "multiclass_assisted_spanish = df_multiclass.dropna().values.tolist()\n",
    "check_labels(df_multiclass, \"Is_policy\")\n",
    "del df_binary\n",
    "del df_multiclass        \n",
    "# print(df_binary[0:5])\n",
    "# print(List_multiclass[0:5])\n",
    "print(len(binary_assisted_spanish))\n",
    "print(len(multiclass_assisted_spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging chile+El Salvador with Mexico assisted labeling datasets\n",
    "binary_assisted_spanish = binary_assisted_spanish + binary_assisted_mexico\n",
    "multiclass_assisted_spanish = multiclass_assisted_spanish + multiclass_assisted_mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4524\n",
      "1359\n"
     ]
    }
   ],
   "source": [
    "print(len(binary_assisted_spanish))\n",
    "print(len(multiclass_assisted_spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Loan' 'Direct payment' 'Fine' nan 'Supplies' 'Tax benefit'\n",
      " 'Technical assistance']\n",
      "702\n",
      "341\n"
     ]
    }
   ],
   "source": [
    "#To process the Excel file with hand-picked labeling results for English training data\n",
    "\n",
    "path = \"/home/propietari/Documents/GitHub/policy-data-analyzer/tasks/data_augmentation/input/\" #Linux\n",
    "# path = \"C:/Users/jordi/Documents/GitHub/policy-data-analyzer/tasks/data_augmentation/input/\" #Windows\n",
    "filename = \"WRI_Policy_Tags_Spanish.xlsx\"\n",
    "file = path + filename\n",
    "\n",
    "df_temp = pd.concat(pd.read_excel(file, engine='openpyxl', sheet_name = None, usecols = \"B:D\"), ignore_index = True)\n",
    "df_temp.loc[df_temp['Incentive'] == 1.0, 'Incentive'] = \"Incentive\"\n",
    "df_temp.loc[df_temp['Incentive'] == 0.0, 'Incentive'] = \"not_Incentive\"\n",
    "df_temp['Primary Instrument'] = df_temp['Primary Instrument'].str.strip()\n",
    "df_temp.loc[df_temp['Primary Instrument'] == \"Unknown\", 'Primary Instrument'] = np.NaN\n",
    "df_temp.loc[df_temp['Primary Instrument'] == \"Other\", 'Primary Instrument'] = np.NaN\n",
    "df_temp.loc[df_temp['Primary Instrument'] == \"Tax deduction\", 'Primary Instrument'] = \"Tax benefit\"\n",
    "df_temp.loc[df_temp['Primary Instrument'] == \"Interest subvention\", 'Primary Instrument'] = \"Loan\"\n",
    "df_temp.loc[df_temp['Primary Instrument'] == \"Credit\", 'Primary Instrument'] = \"Loan\"\n",
    "df_temp.loc[df_temp['Primary Instrument'] == \"Guarantee\", 'Primary Instrument'] = \"Loan\"\n",
    "\n",
    "binary_handpicked_spanish = df_temp[[\"Sentence\", \"Incentive\"]].values.tolist()\n",
    "multiclass_handpicked_spanish = df_temp[[\"Sentence\", \"Primary Instrument\"]].dropna().values.tolist()\n",
    "check_labels(df_temp, \"Primary Instrument\")\n",
    "print(len(binary_handpicked_spanish))\n",
    "print(len(multiclass_handpicked_spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_counter = {\"Loan\" : 0, \"Direct payment\" : 0, \"Fine\" : 0, \"Supplies\" : 0, \"Tax benefit\" : 0, \"Technical assistance\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5226\n",
      "1700\n"
     ]
    }
   ],
   "source": [
    "#Create merges for assited labeling dataset and hand-picked dataset\n",
    "\n",
    "binary_merged_spanish = binary_assisted_spanish + binary_handpicked_spanish\n",
    "multiclass_merged_spanish = multiclass_assisted_spanish + multiclass_handpicked_spanish\n",
    "\n",
    "print(len(binary_merged_spanish))\n",
    "print(len(multiclass_merged_spanish))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of the experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiments = {\"binary_assisted_english\" : binary_assisted_english,\n",
    "#                \"binary_handpicked_english\" : binary_handpicked_english,\n",
    "#                \"binary_merged_English\" : binary_merged_English,\n",
    "#                \"multiclass_assisted_english\" : multiclass_assisted_english,\n",
    "#                \"multiclass_handpicked_english\" : multiclass_handpicked_english,\n",
    "#                \"multiclass_merged_English\" : multiclass_merged_English\n",
    "# }\n",
    "experiments = {\"binary_assisted_spanish\" : binary_assisted_spanish,\n",
    "               \"binary_handpicked_spanish\" : binary_handpicked_spanish,\n",
    "               \"binary_merged_spanish\" : binary_merged_spanish,\n",
    "               \"multiclass_assisted_spanish\" : multiclass_assisted_spanish,\n",
    "               \"multiclass_handpicked_spanish\" : multiclass_handpicked_spanish,\n",
    "               \"multiclass_merged_spanish\" : multiclass_merged_spanish\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perc = 0.2\n",
    "system = \"linux\"\n",
    "\n",
    "for name, data in experiments.items():\n",
    "    sentences = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(sentences, labels, test_size=test_perc, stratify=labels, random_state=69420)\n",
    "    save_data(X_train, y_train, X_test, y_test, name, system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
