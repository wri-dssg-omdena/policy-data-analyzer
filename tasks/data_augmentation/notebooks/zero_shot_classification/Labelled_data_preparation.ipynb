{
 "cells": [
  {

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",

    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dict = {'Credit' : 'Credit', 'Direct' : 'Direct payment', 'Fine' : 'Fine', 'General' : 'Unknown', \n",
    "               'Guarantee' : 'Credit', 'Supplies' : 'Supplies', 'Tax' : 'Tax deduction', \n",
    "               'Technical' : 'Technical assistance', 'Unknown' : 'Unknown', 'Other' : 'Unknown', 'Nan' : 'Unknown' }\n",

    "policy_counter = {\"Credit\" : 0, \"Direct payment\" : 0, \"Fine\" : 0, \"Supplies\" : 0, \"Tax deduction\" : 0, \"Technical assistance\" : 0}\n",
    "incentive_counter = {\"Incentive\" : 0, \"not_Incentive\" : 0}\n",
    "\n",
    "incentive_dict = {'Incentive' : 'Incentive', 'Disincentive' : 'Incentive', 'Unknown' : 'not_Incentive', 'Nan' : 'not_Incentive'}"
   ]
  },
  {

   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_df(df, reference_column_to_drop_na):\n",
    "    df.dropna(subset = [reference_column_to_drop_na], inplace = True)\n",
    "    df.dropna(axis=1, how='all', inplace = True)\n",
    "    df.replace(np.nan, 'Nan', regex=True, inplace = True)\n",
    "    return df\n",
    "\n",
    "def process_new_labels(filename, reference_column_to_drop_na, policy):\n",
    "    df_temp = pd.concat(pd.read_excel(filename, engine='openpyxl', sheet_name = None, skiprows=[0]), ignore_index = True)\n",
    "    df_temp = clean_df(df_temp, reference_column_to_drop_na)\n",
    "    df_temp.insert(0, \"Document\", df_temp.apply(lambda row: row.Sentence_Id.split(\"_\")[0], axis = 1))\n",
    "    df_temp.loc[df_temp['Is_policy'] == 0, 'Is_policy'] = \"Nan\"\n",
    "    df_temp.loc[df_temp['Is_policy'] == 1, 'Is_policy'] = policy\n",
    "    if \"Other_instrument\"in df_temp.columns:\n",
    "        df_temp['Is_policy'] = np.where(df_temp['Is_policy'] == \"Nan\", df_temp['Other_instrument'], df_temp['Is_policy'])\n",
    "    df_temp.loc[df_temp['Is_incentive'] == 0, 'Is_incentive'] = \"Unknown\"\n",
    "    df_temp.loc[df_temp['Is_incentive'] == 1, 'Is_incentive'] = \"Incentive\"\n",
    "    return df_temp\n",
    "\n",
    "def label_cleaning(dictionaryionary, label):\n",
    "    flag = 1\n",
    "    \n",
    "    for key in dictionaryionary:\n",
    "#         print(key, \"----\", label)\n",
    "        if key in label:\n",
    "            return dictionaryionary[key]\n",
    "            flag = 0\n",
    "            break\n",
    "    if flag == 1:\n",
    "#         print(label)\n",
    "        return label\n",
    "\n",
    "def merge_excel_to_list_new(filename):\n",
    "    flag = False\n",
    "    \n",
    "    for policy in policy_dict:\n",
    "        if policy in filename:\n",
    "            policy_instrument = policy\n",
    "            flag = True\n",
    "    if flag:\n",
    "#         print(filename)\n",
    "        df = process_new_labels(filename, \"Is_incentive\", policy_instrument)\n",
    "        List = df[[\"Document\", \"Sentence_Id\", \"Sentence\", \"Is_policy\", \"Is_incentive\"]].values.tolist()\n",
    "    \n",
    "    return List\n",
    "\n",
    "def merge_excel_to_list_old(filename):\n",
    "    df = pd.concat(pd.read_excel(filename, engine='openpyxl', sheet_name = None), ignore_index = True)\n",
    "    df = clean_df(df, \"Document\")\n",
    "    df = df[[\"Document\", \"Sentence\", \"Primary_Instrument\", \"Category\"]]\n",
    "    data = df.values.tolist()\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def list_to_dict(List, dictionary, dataset):\n",
    "    Dictionary = {}\n",
    "    i = 0\n",
    "    for item in List:\n",
    "        i += 1\n",
    "        if dataset == \"Old\":\n",
    "            Dictionary[str(i)] = {\"text\" : item[1], \"labels\" : label_cleaning(policy_dict, item [2]), \"incentive\": label_cleaning(incentive_dict, item [3])}\n",
    "        elif dataset == \"New\":\n",
    "            dictionary[item[1]] = {\"text\" : item[2], \"labels\" : label_cleaning(policy_dict, item [3]), \"incentive\": label_cleaning(incentive_dict, item [4])}\n",
    "    if dataset == \"Old\":\n",
    "        return Dictionary\n",
    "    elif dataset == \"New\":\n",
    "        return dictionary\n",
    "        \n",
    "    \n",
    "\n",
    "def dictionary_to_final_lists(dictionary, classifier):\n",
    "    all_sents = []\n",
    "    all_labels = []\n",
    "        \n",
    "    for item in dictionary:\n",
    "        if classifier == \"Binary\":\n",
    "            all_sents.append(dictionary[item][\"text\"])\n",
    "            all_labels.append(dictionary[item][\"incentive\"])\n",
    "        elif classifier == \"Multiclass\":\n",
    "            if dictionary[item][\"labels\"] != \"Unknown\":\n",
    "                all_sents.append(dictionary[item][\"text\"])\n",
    "                all_labels.append(dictionary[item][\"labels\"])\n",
    "    \n",
    "    return all_sents, all_labels\n",
    "        \n",
    "\n",
    "def save_data(X_train, y_train, X_test, y_test, experiment, classifier):\n",
    "    base_path = \"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\"\n",
    "    \n",
    "    path = base_path + classifier + \"/\"\n",
    "    \n",
    "    filename = \"{}_train_sentences.csv\".format(experiment)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_train))\n",
    "\n",
    "    filename = \"{}_train_labels.csv\".format(experiment)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_train))\n",
    "\n",
    "    filename = \"{}_test_sentences.csv\".format(experiment)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(X_test))\n",
    "\n",
    "    filename = \"{}_test_labels.csv\".format(experiment)\n",
    "    file = path + filename\n",
    "    with open(file, 'w', newline='', encoding='utf-8') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerows(zip(y_test))\n",
    "        \n",
    "def load_dictionary(file):\n",
    "    with open(file, 'r') as f:\n",
    "        dictionary = json.load(f)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raters multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test_perc = 0.2\n",
    "rater = \"Rater1\"\n",
    "classifier = \"Multiclass\"\n",
    "base_path = Path(\"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/{}/\".format(rater))\n",
    "data_path = base_path.glob('**/')\n",
    "\n",
    "for path in data_path:\n",
    "#         results_list = []    \n",
    "    path_in_str = str(path)\n",
    "#         print(path_in_str)\n",
    "    if rater in path_in_str:\n",
    "        dictionary = {}\n",
    "#         print(path_in_str)\n",
    "        for file_obj in Path(path_in_str).glob('*.xlsx'):\n",
    "            file = str(file_obj)\n",
    "            if \"Unique\" in file:\n",
    "                print(file)\n",
    "                dictionary_new_labels = list_to_dict(merge_excel_to_list_new(file), dictionary, \"New\")\n",
    "            else:\n",
    "#                 print(file)\n",
    "                dictionary_old_labels = list_to_dict(merge_excel_to_list_old(file), dictionary, \"Old\")\n",
    "                all_sents_old, all_labels_old = dictionary_to_final_lists(dictionary_old_labels, classifier)\n",
    "                \n",
    "        all_sents_new, all_labels_new = dictionary_to_final_lists(dictionary_new_labels, classifier)\n",
    "print(len(all_sents_old), \" -- \", len(all_labels_old))\n",
    "print(len(all_sents_new), \" -- \", len(all_labels_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"EXP3\", \"EXP9\", \"EXP15\"]\n",
    "if rater == \"Rater3\" and classifier == \"Multiclass\":\n",
    "    for experiment in experiments:\n",
    "        if experiment == \"EXP3\":\n",
    "            X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "            save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "        if experiment == \"EXP9\":\n",
    "            save_data(all_sents_new, all_labels_new, all_sents_old, all_labels_old, experiment, classifier)\n",
    "        if experiment == \"EXP15\":\n",
    "            all_sents = all_sents_new + all_sents_old\n",
    "            all_labels = all_labels_new + all_labels_old\n",
    "            X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "            save_data(X_train, y_train, X_test, y_test, experiment, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"EXP1\", \"EXP7\", \"EXP13\"]\n",
    "if rater == \"Rater1\" and classifier == \"Multiclass\":\n",
    "    for experiment in experiments:\n",
    "        if experiment == \"EXP1\":\n",
    "            X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "            save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "        if experiment == \"EXP7\":\n",
    "            save_data(all_sents_new, all_labels_new, all_sents_old, all_labels_old, experiment, classifier)\n",
    "        if experiment == \"EXP13\":\n",
    "            all_sents = all_sents_new + all_sents_old\n",
    "            all_labels = all_labels_new + all_labels_old\n",
    "            X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "            save_data(X_train, y_train, X_test, y_test, experiment, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"EXP2\", \"EXP8\", \"EXP14\"]\n",
    "if rater == \"Rater2\" and classifier == \"Multiclass\":\n",
    "    for experiment in experiments:\n",
    "        if experiment == \"EXP2\":\n",
    "            X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "            save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "        if experiment == \"EXP8\":\n",
    "            save_data(all_sents_new, all_labels_new, all_sents_old, all_labels_old, experiment, classifier)\n",
    "        if experiment == \"EXP14\":\n",
    "            all_sents = all_sents_new + all_sents_old\n",
    "            all_labels = all_labels_new + all_labels_old\n",
    "            X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "            save_data(X_train, y_train, X_test, y_test, experiment, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raters = [\"Rater1\", \"Rater2\", \"Rater3\"]\n",
    "only_raters = [True, False]\n",
    "# base_path = Path(\"C:/Users/jordi/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\")\n",
    "base_path = Path(\"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/\")\n",
    "\n",
    "for rater in raters:\n",
    "    for only_rater in only_raters:\n",
    "        wraping_up(base_path, rater, only_rater)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merges multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raters = {\"Rater1\" : rater1, \"Rater2\" : rater2, \"Rater3\" : rater3}\n",
    "test_perc = 0.2\n",
    "classifier = \"Multiclass\"\n",
    "\n",
    "all = {}\n",
    "rater1 = {}\n",
    "rater2 = {}\n",
    "rater3 = {}\n",
    "\n",
    "for rater in raters:\n",
    "    base_path = Path(\"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/{}/\".format(rater))\n",
    "    data_path = base_path.glob('**/')\n",
    "\n",
    "    for path in data_path:\n",
    "    #         results_list = []    \n",
    "        path_in_str = str(path)\n",
    "    #         print(path_in_str)\n",
    "        if rater in path_in_str:\n",
    "            dictionary = {}\n",
    "    #         print(path_in_str)\n",
    "            for file_obj in Path(path_in_str).glob('*.xlsx'):\n",
    "                file = str(file_obj)\n",
    "                if \"Unique\" in file:\n",
    "                    dictionary_new_labels = list_to_dict(merge_excel_to_list_new(file), dictionary, \"New\")\n",
    "                else:\n",
    "                    dictionary_old_labels = list_to_dict(merge_excel_to_list_old(file), dictionary, \"Old\")\n",
    "                    all_old, all_labels_old = dictionary_to_final_lists(dictionary_old_labels, classifier)\n",
    "                    \n",
    "            if \"Rater1\" in path_in_str:\n",
    "                rater1 = dictionary_new_labels\n",
    "            elif \"Rater2\" in path_in_str:\n",
    "                rater2 = dictionary_new_labels          \n",
    "            elif \"Rater3\" in path_in_str:\n",
    "                rater3 = dictionary_new_labels\n",
    "all = {**rater1, **rater2, **rater3}\n",
    "\n",
    "print(len(rater1), len(rater2), len(rater3), len(all))\n",
    "\n",
    "# Next we loop for the dictionary to find the elements that meet the criteria of the different merges.\n",
    "\n",
    "incentive = \"labels\" #write \"labels\" if you want to work with policy instruments, write \"incentive\" to work with is_incentive\n",
    "merge1 = {}\n",
    "merge2 = {}\n",
    "merge3 = {}\n",
    "# classifier = \"labels\" #If you want to classify by is_incentive\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "n = 0\n",
    "# First we look for sentences that all three raters have labeled the same\n",
    "for sent in all:\n",
    "    i += 1\n",
    "    if sent in rater1 and sent in rater2 and sent in rater3:\n",
    "        j += 1\n",
    "        if rater1[sent][\"labels\"] == rater2[sent][\"labels\"] and rater2[sent][\"labels\"] == rater3[sent][\"labels\"]:\n",
    "            k += 1\n",
    "            if rater1[sent][\"labels\"] != 'Unknown':\n",
    "                merge3[sent] = rater1[sent]\n",
    "\n",
    "#Now we look for the sentences that at least two raters have labeled the same\n",
    "for sent in all:\n",
    "    if sent in rater1 and sent in rater2:\n",
    "        l += 1\n",
    "        if rater1[sent][\"labels\"] == rater2[sent][\"labels\"]:\n",
    "            if rater1[sent][\"labels\"] != 'Unknown':\n",
    "                m += 1\n",
    "                merge2[sent] = rater1[sent]\n",
    "    elif sent in rater1 and sent in rater3:\n",
    "        l += 1\n",
    "        if rater1[sent][\"labels\"] == rater3[sent][\"labels\"]:\n",
    "            if rater1[sent][\"labels\"] != 'Unknown':\n",
    "                m += 1\n",
    "                merge2[sent] = rater1[sent]\n",
    "    elif sent in rater2 and sent in rater3:\n",
    "        l += 1\n",
    "        if rater2[sent][\"labels\"] == rater3[sent][\"labels\"]:\n",
    "            if rater2[sent][\"labels\"] != 'Unknown':\n",
    "                m += 1\n",
    "                merge2[sent] = rater2[sent]\n",
    "            \n",
    "# Finally we build a dataset containing the sentences that at least one of the labelers have labeled with a label different from \"Unknown\"\n",
    "for sent in all:\n",
    "    label = {}\n",
    "    if sent in rater3 and rater3[sent][\"labels\"] != 'Unknown':\n",
    "#         label[rater3[sent][\"labels\"]] = \"rater3\"\n",
    "        merge1[sent] = rater3[sent]\n",
    "    elif sent in rater2 and rater2[sent][\"labels\"] != 'Unknown':\n",
    "#         label[rater2[sent][\"labels\"]] = \"rater2\"\n",
    "        merge1[sent] = rater2[sent]\n",
    "    elif sent in rater1 and rater1[sent][\"labels\"] != 'Unknown':\n",
    "#         label[rater1[sent][\"labels\"]] = \"rater1\"\n",
    "        merge1[sent] = rater1[sent]\n",
    "#     else:\n",
    "#         merge1[sent] = all[sent]\n",
    "\n",
    "print(f\"In the all-sentences dict there are {i} sentences\")\n",
    "print(f\"In the three raters lists there are {j} common sentences\")\n",
    "print(f\"In the three raters lists there are {k} common sentences which are rated identically\")\n",
    "print(f\"There are {l} sentences which are comon to at lest two rater's datasets\")\n",
    "print(f\"There are {m} sentences which are labeled identical in at least two rater's datasets\")\n",
    "print(len(merge3))\n",
    "print(len(merge2))\n",
    "print(len(merge1))\n",
    "\n",
    "merges = {\"Merge1\" : merge1, \"Merge2\" : merge2, \"Merge3\" : merge3}\n",
    "for merge in merges:\n",
    "    all_new = []\n",
    "    all_labels_new = []\n",
    "    for sent in merges[merge]:\n",
    "        all_new.append(merges[merge][sent][\"text\"])\n",
    "        all_labels_new.append(merges[merge][sent][\"labels\"])\n",
    "    print(merge)\n",
    "    if merge == \"Merge1\" and classifier == \"Multiclass\":\n",
    "        experiments = [\"EXP4\", \"EXP10\", \"EXP16\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP4\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP10\":\n",
    "                save_data(all_new, all_labels_new, all_old, all_labels_old, experiment, classifier)\n",
    "            if experiment == \"EXP16\":\n",
    "                all = all_new + all_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "    \n",
    "    if merge == \"Merge2\" and classifier == \"Multiclass\":\n",
    "        experiments = [\"EXP5\", \"EXP11\", \"EXP17\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP5\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP11\":\n",
    "                save_data(all_new, all_labels_new, all_old, all_labels_old, experiment, classifier)\n",
    "            if experiment == \"EXP17\":\n",
    "                all = all_new + all_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "                \n",
    "    if merge == \"Merge3\" and classifier == \"Multiclass\":\n",
    "        experiments = [\"EXP6\", \"EXP12\", \"EXP18\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP6\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP12\":\n",
    "                save_data(all_new, all_labels_new, all_old, all_labels_old, experiment, classifier)\n",
    "            if experiment == \"EXP18\":\n",
    "                all = all_new + all_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raters binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_perc = 0.2\n",
    "# rater = \"Rater1\"\n",
    "classifier = \"Binary\"\n",
    "all = {}\n",
    "rater1 = {}\n",
    "rater2 = {}\n",
    "rater3 = {}\n",
    "raters = {\"Rater1\" : rater1, \"Rater2\" : rater2, \"Rater3\" : rater3}\n",
    "\n",
    "for rater in raters:\n",
    "    base_path = Path(\"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/{}/\".format(rater))\n",
    "    data_path = base_path.glob('**/')\n",
    "\n",
    "    for path in data_path:\n",
    "    #         results_list = []    \n",
    "        path_in_str = str(path)\n",
    "    #         print(path_in_str)\n",
    "        if rater in path_in_str:\n",
    "            dictionary = {}\n",
    "    #         print(path_in_str)\n",
    "            for file_obj in Path(path_in_str).glob('*.xlsx'):\n",
    "                file = str(file_obj)\n",
    "                if \"Unique\" in file:\n",
    "#                     print(file)\n",
    "                    dictionary_new_labels = list_to_dict(merge_excel_to_list_new(file), dictionary, \"New\")\n",
    "                else:\n",
    "    #                 print(file)\n",
    "                    dictionary_old_labels = list_to_dict(merge_excel_to_list_old(file), dictionary, \"Old\")\n",
    "                    all_sents_old, all_labels_old = dictionary_to_final_lists(dictionary_old_labels, classifier)\n",
    "            if \"Rater1\" in path_in_str:\n",
    "                raters[rater] = dictionary_new_labels\n",
    "            elif \"Rater2\" in path_in_str:\n",
    "                raters[rater] = dictionary_new_labels          \n",
    "            elif \"Rater3\" in path_in_str:\n",
    "                raters[rater] = dictionary_new_labels\n",
    "# all = {**rater1, **rater2, **rater3}\n",
    "\n",
    "    unknown = 0\n",
    "    known = 0\n",
    "    bugs = 0\n",
    "    all_sents_new = []\n",
    "    all_labels_new = []\n",
    "    for sent in raters[rater]:\n",
    "        all_sents_new.append(raters[rater][sent][\"text\"])\n",
    "        all_labels_new.append(raters[rater][sent][\"incentive\"])\n",
    "        if raters[rater][sent][\"incentive\"] == \"not_Incentive\":\n",
    "            unknown += 1\n",
    "        elif raters[rater][sent][\"incentive\"] == \"Incentive\":\n",
    "            known += 1\n",
    "        else:\n",
    "            bugs += 1\n",
    "    print(rater)\n",
    "    print(len(raters[rater]))\n",
    "    print(\"Incentive\", known, \" -- not_Incentive\", unknown, \" -- Others\", bugs)\n",
    "\n",
    "    if rater == \"Rater1\" and classifier == \"Binary\":\n",
    "        experiments = [\"EXP19\", \"EXP25\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP19\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP25\":\n",
    "                all_sents = all_sents_new + all_sents_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "                \n",
    "    if rater == \"Rater2\" and classifier == \"Binary\":\n",
    "        experiments = [\"EXP20\", \"EXP26\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP20\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP26\":\n",
    "                all_sents = all_sents_new + all_sents_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "                \n",
    "    if rater == \"Rater3\" and classifier == \"Binary\":\n",
    "        experiments = [\"EXP21\", \"EXP27\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP21\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP27\":\n",
    "                all_sents = all_sents_new + all_sents_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merges binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the all-sentences dict there are 2627 sentences\n",
      "In the three raters lists there are 533 common sentences\n",
      "In the three raters lists there are 324 common sentences which are rated identically\n",
      "There are 1898 sentences which are comon to at lest two rater's datasets\n",
      "There are 1359 sentences which are labeled identical in at least two rater's datasets\n",
      "324\n",
      "1359\n",
      "2627\n",
      "Merge1\n",
      "Merge2\n",
      "Merge3\n"
     ]
    }
   ],
   "source": [
    "test_perc = 0.2\n",
    "# rater = \"Rater1\"\n",
    "classifier = \"Binary\"\n",
    "all = {}\n",
    "rater1 = {}\n",
    "rater2 = {}\n",
    "rater3 = {}\n",
    "raters = {\"Rater1\" : rater1, \"Rater2\" : rater2, \"Rater3\" : rater3}\n",
    "\n",
    "for rater in raters:\n",
    "    base_path = Path(\"C:/Users/user/Google Drive/Els_meus_documents/projectes/CompetitiveIntelligence/WRI/Notebooks/Data/Final_input_data/{}/\".format(rater))\n",
    "    data_path = base_path.glob('**/')\n",
    "\n",
    "    for path in data_path:\n",
    "    #         results_list = []    \n",
    "        path_in_str = str(path)\n",
    "    #         print(path_in_str)\n",
    "        if rater in path_in_str:\n",
    "            dictionary = {}\n",
    "    #         print(path_in_str)\n",
    "            for file_obj in Path(path_in_str).glob('*.xlsx'):\n",
    "                file = str(file_obj)\n",
    "                if \"Unique\" in file:\n",
    "#                     print(file)\n",
    "                    dictionary_new_labels = list_to_dict(merge_excel_to_list_new(file), dictionary, \"New\")\n",
    "                else:\n",
    "    #                 print(file)\n",
    "                    dictionary_old_labels = list_to_dict(merge_excel_to_list_old(file), dictionary, \"Old\")\n",
    "                    all_sents_old, all_labels_old = dictionary_to_final_lists(dictionary_old_labels, classifier)\n",
    "            if \"Rater1\" in path_in_str:\n",
    "                rater1 = dictionary_new_labels\n",
    "            elif \"Rater2\" in path_in_str:\n",
    "                rater2 = dictionary_new_labels          \n",
    "            elif \"Rater3\" in path_in_str:\n",
    "                rater3 = dictionary_new_labels\n",
    "\n",
    "all = {**rater1, **rater2, **rater3}\n",
    "\n",
    "\n",
    "incentive = \"incentive\" #write incentive if you want to work with policy instruments, write \"incentive\" to work with is_incentive\n",
    "merge1 = {}\n",
    "merge2 = {}\n",
    "merge3 = {}\n",
    "# classifier = incentive #If you want to classify by is_incentive\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "k = 0\n",
    "l = 0\n",
    "m = 0\n",
    "n = 0\n",
    "# First we look for sentences that all three raters have labeled the same\n",
    "for sent in all:\n",
    "    i += 1\n",
    "    if sent in rater1 and sent in rater2 and sent in rater3:\n",
    "        j += 1\n",
    "        if rater1[sent][incentive] == rater2[sent][incentive] and rater2[sent][incentive] == rater3[sent][incentive]:\n",
    "            k += 1\n",
    "            merge3[sent] = rater1[sent]\n",
    "\n",
    "#Now we look for the sentences that at least two raters have labeled the same\n",
    "for sent in all:\n",
    "    if sent in rater1 and sent in rater2:\n",
    "        l += 1\n",
    "        if rater1[sent][incentive] == rater2[sent][incentive]:\n",
    "            m += 1\n",
    "            merge2[sent] = rater1[sent]\n",
    "    elif sent in rater1 and sent in rater3:\n",
    "        l += 1\n",
    "        if rater1[sent][incentive] == rater3[sent][incentive]:\n",
    "            m += 1\n",
    "            merge2[sent] = rater1[sent]\n",
    "    elif sent in rater2 and sent in rater3:\n",
    "        l += 1\n",
    "        if rater2[sent][incentive] == rater3[sent][incentive]:\n",
    "            m += 1\n",
    "            merge2[sent] = rater2[sent]\n",
    "            \n",
    "# Finally we build a dataset containing the sentences that at least one of the labelers have labeled\n",
    "for sent in all:\n",
    "    label = {}\n",
    "    if sent in rater3:\n",
    "#         label[rater3[sent][incentive]] = \"rater3\"\n",
    "        merge1[sent] = rater3[sent]\n",
    "    elif sent in rater2:\n",
    "#         label[rater2[sent][incentive]] = \"rater2\"\n",
    "        merge1[sent] = rater2[sent]\n",
    "    elif sent in rater1:\n",
    "#         label[rater1[sent][incentive]] = \"rater1\"\n",
    "        merge1[sent] = rater1[sent]\n",
    "#     else:\n",
    "#         merge1[sent] = all[sent]\n",
    "\n",
    "print(f\"In the all-sentences dict there are {i} sentences\")\n",
    "print(f\"In the three raters lists there are {j} common sentences\")\n",
    "print(f\"In the three raters lists there are {k} common sentences which are rated identically\")\n",
    "print(f\"There are {l} sentences which are comon to at lest two rater's datasets\")\n",
    "print(f\"There are {m} sentences which are labeled identical in at least two rater's datasets\")\n",
    "print(len(merge3))\n",
    "print(len(merge2))\n",
    "print(len(merge1))\n",
    "\n",
    "merges = {\"Merge1\" : merge1, \"Merge2\" : merge2, \"Merge3\" : merge3}\n",
    "for merge in merges:\n",
    "    all_sents_new = []\n",
    "    all_labels_new = []\n",
    "    for sent in merges[merge]:\n",
    "        all_sents_new.append(merges[merge][sent][\"text\"])\n",
    "        all_labels_new.append(merges[merge][sent][incentive])\n",
    "    print(merge)\n",
    "    \n",
    "    if merge == \"Merge1\" and classifier == \"Binary\":\n",
    "        experiments = [\"EXP22\", \"EXP28\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP22\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP28\":\n",
    "                all_sents = all_sents_new + all_sents_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "                \n",
    "    if merge == \"Merge2\" and classifier == \"Binary\":\n",
    "        experiments = [\"EXP23\", \"EXP29\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP23\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP29\":\n",
    "                all_sents = all_sents_new + all_sents_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "                \n",
    "    if merge == \"Merge3\" and classifier == \"Binary\":\n",
    "        experiments = [\"EXP24\", \"EXP30\"]\n",
    "        for experiment in experiments:\n",
    "            if experiment == \"EXP24\":\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents_new, all_labels_new, test_size=test_perc, stratify=all_labels_new, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)\n",
    "            if experiment == \"EXP30\":\n",
    "                all_sents = all_sents_new + all_sents_old\n",
    "                all_labels = all_labels_new + all_labels_old\n",
    "                X_train, X_test, y_train, y_test = train_test_split(all_sents, all_labels, test_size=test_perc, stratify=all_labels, random_state=69420)\n",
    "                save_data(X_train, y_train, X_test, y_test, experiment, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
